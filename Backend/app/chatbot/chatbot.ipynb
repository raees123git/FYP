{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa220f83",
   "metadata": {},
   "source": [
    "## Debug - Check User Collection Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafbcb86",
   "metadata": {},
   "source": [
    "# Intelligent Chatbot Routing System with LangGraph\n",
    "\n",
    "This notebook implements an automated chatbot routing system that intelligently directs user queries to the appropriate agent without requiring manual selection.\n",
    "\n",
    "## Architecture\n",
    "- **Supervisor Agent**: Analyzes user queries and routes to appropriate sub-agent\n",
    "- **Resume Agent**: Handles resume-related queries using FAISS vector DB\n",
    "- **Reports Agent**: Handles interview reports and analytics queries using MongoDB\n",
    "- **General Question Agent**: Handles general questions and conversation\n",
    "\n",
    "## Database Integration\n",
    "- **FAISS Vector DB**: For semantic search on user resumes\n",
    "- **MongoDB**: For fetching interview reports and analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3241b",
   "metadata": {},
   "source": [
    "## âœ… Updates to Match Production Chatbot\n",
    "\n",
    "This LangGraph implementation now matches the behavior of the deployed chatbot on the website:\n",
    "\n",
    "### Reports Agent\n",
    "- **Fetches detailed report types**: `verbal_reports`, `nonverbal_reports`, `overall_reports` collections\n",
    "- **Passes FULL report data as JSON** to Gemini LLM\n",
    "- **Extracts specific metrics**: WPM, pace, scores, feedback from structured report data\n",
    "- **Example**: \"What is my WPM?\" â†’ Returns exact value (81) from nonverbal report\n",
    "\n",
    "### Resume Agent\n",
    "- **Uses FAISS vector database** for semantic search on resume content\n",
    "- **Returns specific information** from indexed resume chunks\n",
    "- **Example**: \"What programming languages do I know?\" â†’ Lists Python, Javascript, Java, Go\n",
    "\n",
    "### General Agent\n",
    "- **Uses SkillEdge-AI knowledge base** for platform information\n",
    "- **Handles greetings and platform questions**\n",
    "- **Example**: \"What is SkillEdge-AI?\" â†’ Explains platform features\n",
    "\n",
    "### Supervisor Agent\n",
    "- **Intelligent routing** based on query intent\n",
    "- **Routes WPM/performance metrics to reports agent** (not resume)\n",
    "- **Recognizes patterns**: resume content, interview metrics, general questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d4f4b",
   "metadata": {},
   "source": [
    "## âœ… Resume Query Fix - Matching Production Behavior\n",
    "\n",
    "**Problem Solved**: The chatbot was incorrectly stating you know Java and Go.\n",
    "\n",
    "### Root Cause\n",
    "1. **Faulty skills extraction** in `resume_parser.py` used substring matching:\n",
    "   - \"**java**\" matched inside \"**Java**script\"\n",
    "   - \"**go**\" matched in \"Lan**g**chain\", \"**go**al\", etc.\n",
    "\n",
    "2. **Using `top_k=5`** retrieved less relevant chunks including the faulty metadata chunk\n",
    "\n",
    "### Solution Applied\n",
    "1. **Updated `resume_parser.py`**: Now uses word boundary regex (`\\b`) to match whole words only\n",
    "2. **Changed to `top_k=3`**: Matches production setting, retrieves only most relevant chunks\n",
    "3. **Improved prompt**: Simplified to match production's direct instruction style\n",
    "\n",
    "### Test Results\n",
    "âœ… \"which programming languages do i know?\" â†’ Returns \"Python and Javascript\"\n",
    "âœ… \"do i know java?\" â†’ Returns \"I couldn't find any mention of Java\"  \n",
    "âœ… \"do i know go?\" â†’ Returns \"I couldn't find any mention of Go\"\n",
    "\n",
    "**Now matches production website behavior perfectly!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5fac03",
   "metadata": {},
   "source": [
    "## ðŸ”„ Conversation Persistence\n",
    "\n",
    "The chatbot now maintains **conversation history** across messages:\n",
    "\n",
    "- **Stores message history** in `conversation_histories` dictionary\n",
    "- **Provides context** to supervisor for better routing decisions\n",
    "- **Maintains last 10 messages** for context window\n",
    "- **Supports multiple conversations** via `conversation_id` parameter\n",
    "- **Clear history** using `clear_conversation()` function\n",
    "\n",
    "Example:\n",
    "```python\n",
    "# First message\n",
    "await chat(\"What is my WPM?\")  # Routes to reports agent â†’ \"Your WPM is 81\"\n",
    "\n",
    "# Follow-up message (maintains context)\n",
    "await chat(\"How can I improve it?\")  # Understands \"it\" = WPM â†’ Routes to reports agent â†’ Gives specific advice\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea7ba0",
   "metadata": {},
   "source": [
    "## 1. Install Required Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b579e",
   "metadata": {},
   "source": [
    "## 2. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e8a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "import operator\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "from bson.objectid import ObjectId\n",
    "import json\n",
    "\n",
    "# Add parent directory to path to import app modules\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\"../../.env\")\n",
    "print(\"âœ… Environment variables loaded\")\n",
    "\n",
    "# Import resume RAG service and database functions\n",
    "from app.chatbot.resume_rag import get_resume_rag_service\n",
    "from app.database import (\n",
    "    connect_to_mongo, \n",
    "    get_interview_reports_collection, \n",
    "    get_overall_reports_collection, \n",
    "    get_users_collection,\n",
    "    get_verbal_reports_collection,\n",
    "    get_nonverbal_reports_collection\n",
    ")\n",
    "\n",
    "print(\"âœ… Imported resume RAG service and database modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d30b34a",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d884370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Gemini API key from .env file\n",
    "GEMINI_API_KEY2 = os.getenv(\"GEMINI_API_KEY2\")\n",
    "\n",
    "if not GEMINI_API_KEY2:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env file. Please add it to Backend/.env\")\n",
    "\n",
    "print(f\"âœ… API Key loaded: {GEMINI_API_KEY2[:10]}...\")\n",
    "\n",
    "# Set environment variable for Google\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY2\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.3,\n",
    "    convert_system_message_to_human=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Gemini LLM initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd918f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MongoDB connection\n",
    "try:\n",
    "    await connect_to_mongo()\n",
    "    print(\"âœ… MongoDB connected successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ MongoDB connection failed: {e}\")\n",
    "\n",
    "# Initialize Resume RAG service\n",
    "try:\n",
    "    resume_rag = get_resume_rag_service()\n",
    "    \n",
    "    # Fix the index path to be relative to current working directory (notebook location)\n",
    "    # Current: d:\\Final Year Project\\Backend\\app\\chatbot\n",
    "    # Need: faiss_index/resumes (since we're already in app/chatbot)\n",
    "    resume_rag.resume_index_path = \"faiss_index/resumes\"\n",
    "    \n",
    "    print(\"âœ… Resume RAG service initialized!\")\n",
    "    print(f\"ðŸ“ Resume index path: {os.path.abspath(resume_rag.resume_index_path)}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Resume RAG initialization failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3395bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure of users in database\n",
    "users_collection = get_users_collection()\n",
    "\n",
    "# Search by _id (MongoDB ObjectId)\n",
    "from bson import ObjectId\n",
    "sample_user = await users_collection.find_one({\"_id\": ObjectId(\"69036f582c287be569c54623\")})\n",
    "\n",
    "if sample_user:\n",
    "    print(\"âœ… Found user in database!\")\n",
    "    print(f\"\\nUser document structure:\")\n",
    "    for key, value in sample_user.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"âŒ User not found with _id: 69036f582c287be569c54623\")\n",
    "    print(\"\\nLet's check what users exist:\")\n",
    "    all_users = await users_collection.find({}).limit(3).to_list(length=3)\n",
    "    for i, user in enumerate(all_users, 1):\n",
    "        print(f\"\\nUser #{i}:\")\n",
    "        print(f\"  _id: {user.get('_id')}\")\n",
    "        print(f\"  email: {user.get('email', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check resume index paths and existence\n",
    "user_id_to_check = \"69036f582c287be569c54623\"\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"\\nChecking resume index for user: {user_id_to_check}\")\n",
    "print(f\"Resume RAG index base path: {resume_rag.resume_index_path}\")\n",
    "\n",
    "# Check if has_resume_index returns True\n",
    "has_index = resume_rag.has_resume_index(user_id_to_check)\n",
    "print(f\"\\nhas_resume_index() returned: {has_index}\")\n",
    "\n",
    "# Check actual file paths\n",
    "index_path = resume_rag._get_user_index_path(user_id_to_check)\n",
    "kb_path = resume_rag._get_user_kb_path(user_id_to_check)\n",
    "\n",
    "print(f\"\\nExpected index file path: {index_path}\")\n",
    "print(f\"Index file exists: {os.path.exists(index_path)}\")\n",
    "\n",
    "print(f\"\\nExpected KB file path: {kb_path}\")\n",
    "print(f\"KB file exists: {os.path.exists(kb_path)}\")\n",
    "\n",
    "# Try with absolute path\n",
    "abs_base = os.path.abspath(\"../../app/chatbot/faiss_index/resumes\")\n",
    "print(f\"\\nAbsolute base path: {abs_base}\")\n",
    "abs_index = os.path.join(abs_base, f\"{user_id_to_check}_resume.index\")\n",
    "abs_kb = os.path.join(abs_base, f\"{user_id_to_check}_resume_kb.pkl\")\n",
    "print(f\"Absolute index path exists: {os.path.exists(abs_index)}\")\n",
    "print(f\"Absolute KB path exists: {os.path.exists(abs_kb)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e32d692",
   "metadata": {},
   "source": [
    "### Initialize Database Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd30b062",
   "metadata": {},
   "source": [
    "## 4. Define State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotState(TypedDict):\n",
    "    \"\"\"State schema for the chatbot graph\"\"\"\n",
    "    messages: Annotated[list, add_messages]  # Chat history\n",
    "    user_query: str  # Current user query\n",
    "    route: str  # Which agent to route to\n",
    "    response: str  # Final response to user\n",
    "    user_id: str  # User identifier (for context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2acf60",
   "metadata": {},
   "source": [
    "## 5. Supervisor Agent - Query Analyzer & Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_agent(state: ChatbotState) -> ChatbotState:\n",
    "    \"\"\"\n",
    "    Supervisor agent that analyzes the user query and determines which sub-agent should handle it.\n",
    "    \n",
    "    Routes:\n",
    "    - resume_agent: Questions about resume, skills, experience, education, projects\n",
    "    - reports_agent: Questions about interview performance, analytics, scores, feedback, WPM, pace, etc.\n",
    "    - general_agent: General conversation, greetings, other questions\n",
    "    \"\"\"\n",
    "    \n",
    "    user_query = state[\"user_query\"]\n",
    "    \n",
    "    # System prompt for the supervisor\n",
    "    supervisor_prompt = \"\"\"You are an intelligent routing agent for a career interview platform chatbot.\n",
    "Your job is to analyze the user's query and decide which specialized agent should handle it.\n",
    "\n",
    "Available agents:\n",
    "1. \"resume\" - Handles questions about:\n",
    "   - User's resume content (skills, experience, education, projects)\n",
    "   - Resume improvements and suggestions\n",
    "   - Career profile information\n",
    "   - Skills assessment\n",
    "   - Professional background\n",
    "\n",
    "2. \"reports\" - Handles questions about:\n",
    "   - Interview performance and scores\n",
    "   - Past interview reports and analytics\n",
    "   - Interview feedback and recommendations\n",
    "   - Performance trends and statistics\n",
    "   - Speaking metrics (WPM, pace, speed, fluency, clarity)\n",
    "   - Verbal analysis (answer quality, domain knowledge, correctness)\n",
    "   - Non-verbal analysis (body language, confidence, voice)\n",
    "   - Any specific performance data or metrics\n",
    "\n",
    "3. \"general\" - Handles:\n",
    "   - General conversation and greetings\n",
    "   - Platform usage questions\n",
    "   - Unrelated or unclear queries\n",
    "   - Small talk\n",
    "\n",
    "Important: Questions about performance metrics like WPM, pace, speed, scores, feedback should go to \"reports\" agent.\n",
    "\n",
    "Analyze the query and respond with ONLY ONE WORD from: resume, reports, or general\n",
    "Do not provide any explanation, just the routing decision.\"\"\"\n",
    "    \n",
    "    # Get routing decision from LLM\n",
    "    messages = [\n",
    "        SystemMessage(content=supervisor_prompt),\n",
    "        HumanMessage(content=f\"User Query: {user_query}\")\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Extract and normalize the route\n",
    "    route = response.content.strip().lower()\n",
    "    \n",
    "    # Validate route\n",
    "    if route not in [\"resume\", \"reports\", \"general\"]:\n",
    "        route = \"general\"  # Default fallback\n",
    "    \n",
    "    print(f\"ðŸ“ Supervisor Decision: Routing to '{route}' agent\")\n",
    "    \n",
    "    state[\"route\"] = route\n",
    "    state[\"messages\"].append(AIMessage(content=f\"[Routing to {route} agent]\"))\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f98662f",
   "metadata": {},
   "source": [
    "## 6. Resume Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c86e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def resume_agent(state: ChatbotState) -> ChatbotState:\n",
    "    \"\"\"\n",
    "    Resume agent handles queries about user's resume, skills, experience, and career profile.\n",
    "    Uses FAISS vector DB for semantic search on actual resume data.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_query = state[\"user_query\"]\n",
    "    user_id = state.get(\"user_id\", \"unknown\")\n",
    "    \n",
    "    try:\n",
    "        # Since there's no user_id field in users collection, use _id directly\n",
    "        # The user_id passed in should be the MongoDB ObjectId string\n",
    "        mongodb_id = user_id\n",
    "        \n",
    "        print(f\"ðŸ“Œ Using MongoDB ID: {mongodb_id} for resume search\")\n",
    "        \n",
    "        # Check if user has a resume indexed\n",
    "        has_resume = resume_rag.has_resume_index(mongodb_id)\n",
    "        \n",
    "        if not has_resume:\n",
    "            response_text = \"I'd love to help you with your resume questions, but I don't see a resume indexed for your account yet. Please upload your resume first, and I'll be able to answer questions about your skills, experience, and projects!\"\n",
    "            print(f\"\\nðŸ“„ Resume Agent Response: {response_text}\\n\")\n",
    "            state[\"response\"] = response_text\n",
    "            state[\"messages\"].append(AIMessage(content=response_text))\n",
    "            return state\n",
    "        \n",
    "        # Use top_k=3 to match production behavior\n",
    "        # Gets the most relevant chunks without including less relevant metadata\n",
    "        resume_results = await resume_rag.search_user_resume(mongodb_id, user_query, top_k=3)\n",
    "        \n",
    "        if not resume_results:\n",
    "            response_text = \"I couldn't find relevant information in your resume for that query. Could you rephrase your question?\"\n",
    "            print(f\"\\nðŸ“„ Resume Agent Response: {response_text}\\n\")\n",
    "            state[\"response\"] = response_text\n",
    "            state[\"messages\"].append(AIMessage(content=response_text))\n",
    "            return state\n",
    "        \n",
    "        # Build context from search results\n",
    "        context_parts = []\n",
    "        for i, result in enumerate(resume_results, 1):\n",
    "            context_parts.append(f\"[Context {i}] {result['content']}\")\n",
    "        \n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "        \n",
    "        print(f\"âœ… Found {len(resume_results)} relevant resume chunks\")\n",
    "        \n",
    "        # System prompt matching production behavior\n",
    "        resume_prompt = f\"\"\"You are SkillEdge-AI Assistant helping users with questions about their resume.\n",
    "\n",
    "Information from the user's resume:\n",
    "{context}\n",
    "\n",
    "User Question: {user_query}\n",
    "\n",
    "Guidelines:\n",
    "- Answer based ONLY on the information provided above from their resume\n",
    "- Be specific and reference actual content from the resume context\n",
    "- Keep responses concise and to the point\n",
    "- If the information isn't in the provided context, say you couldn't find it in their resume\n",
    "\n",
    "Provide your answer:\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=resume_prompt),\n",
    "            HumanMessage(content=user_query)\n",
    "        ]\n",
    "        response = llm.invoke(messages)\n",
    "        \n",
    "        answer = response.content\n",
    "        print(f\"\\nðŸ“„ Resume Agent Response: {answer}\\n\")\n",
    "        \n",
    "        state[\"response\"] = answer\n",
    "        state[\"messages\"].append(AIMessage(content=answer))\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"I encountered an error while searching your resume: {str(e)}\"\n",
    "        print(f\"\\nâŒ Resume Agent Error: {error_msg}\\n\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        state[\"response\"] = error_msg\n",
    "        state[\"messages\"].append(AIMessage(content=error_msg))\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647be9be",
   "metadata": {},
   "source": [
    "## 7. Reports Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def reports_agent(state: ChatbotState) -> ChatbotState:\n",
    "    \"\"\"\n",
    "    Reports agent handles queries about interview performance, analytics, and feedback.\n",
    "    Uses MongoDB to fetch detailed verbal, nonverbal, and overall reports.\n",
    "    Matches the behavior of the implemented chatbot in the website.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_query = state[\"user_query\"]\n",
    "    user_id = state.get(\"user_id\", \"unknown\")\n",
    "    \n",
    "    try:\n",
    "        # Get all report collections (matching the implemented chatbot)\n",
    "        verbal_collection = get_verbal_reports_collection()\n",
    "        nonverbal_collection = get_nonverbal_reports_collection()\n",
    "        overall_collection = get_overall_reports_collection()\n",
    "        \n",
    "        # Find latest verbal report\n",
    "        verbal_report = await verbal_collection.find_one(\n",
    "            {\"user_id\": user_id},\n",
    "            sort=[(\"created_at\", -1)]\n",
    "        )\n",
    "        \n",
    "        # Find latest non-verbal report  \n",
    "        nonverbal_report = await nonverbal_collection.find_one(\n",
    "            {\"user_id\": user_id},\n",
    "            sort=[(\"created_at\", -1)]\n",
    "        )\n",
    "        \n",
    "        # Find latest overall report\n",
    "        overall_report = await overall_collection.find_one(\n",
    "            {\"user_id\": user_id},\n",
    "            sort=[(\"created_at\", -1)]\n",
    "        )\n",
    "        \n",
    "        # Check if user has any reports\n",
    "        if not verbal_report and not nonverbal_report and not overall_report:\n",
    "            response_text = \"I don't see any interview reports for your account yet. Complete an interview to get personalized feedback and analytics!\"\n",
    "            print(f\"\\nðŸ“Š Reports Agent Response: {response_text}\\n\")\n",
    "            state[\"response\"] = response_text\n",
    "            state[\"messages\"].append(AIMessage(content=response_text))\n",
    "            return state\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Reports Agent - Found reports: Verbal={bool(verbal_report)}, NonVerbal={bool(nonverbal_report)}, Overall={bool(overall_report)}\")\n",
    "        \n",
    "        # Helper function to serialize MongoDB documents\n",
    "        def serialize_doc(doc):\n",
    "            \"\"\"Convert MongoDB document to JSON-serializable format\"\"\"\n",
    "            if doc is None:\n",
    "                return None\n",
    "            serialized = {}\n",
    "            for key, value in doc.items():\n",
    "                if key == \"_id\":\n",
    "                    continue  # Skip ObjectId\n",
    "                elif hasattr(value, 'isoformat'):  # datetime\n",
    "                    serialized[key] = value.isoformat()\n",
    "                elif isinstance(value, dict):\n",
    "                    serialized[key] = serialize_doc(value)\n",
    "                elif isinstance(value, list):\n",
    "                    serialized[key] = [serialize_doc(item) if isinstance(item, dict) else item for item in value]\n",
    "                else:\n",
    "                    serialized[key] = value\n",
    "            return serialized\n",
    "        \n",
    "        # Build comprehensive context with FULL report data (like implemented chatbot)\n",
    "        context_text = \"User's Interview Reports:\\n\\n\"\n",
    "        \n",
    "        if verbal_report:\n",
    "            context_text += \"=== VERBAL REPORT ===\\n\"\n",
    "            context_text += json.dumps(serialize_doc(verbal_report), indent=2) + \"\\n\\n\"\n",
    "        \n",
    "        if nonverbal_report:\n",
    "            context_text += \"=== NON-VERBAL REPORT ===\\n\"\n",
    "            context_text += json.dumps(serialize_doc(nonverbal_report), indent=2) + \"\\n\\n\"\n",
    "        \n",
    "        if overall_report:\n",
    "            context_text += \"=== OVERALL REPORT ===\\n\"\n",
    "            context_text += json.dumps(serialize_doc(overall_report), indent=2) + \"\\n\\n\"\n",
    "        \n",
    "        # System prompt matching the implemented chatbot's behavior\n",
    "        reports_prompt = f\"\"\"You are SkillEdge-AI Assistant, an intelligent chatbot for the SkillEdge-AI interview preparation platform.\n",
    "You are analyzing user's interview performance reports.\n",
    "\n",
    "Guidelines:\n",
    "- Be helpful, professional, and encouraging\n",
    "- Provide SPECIFIC answers using the EXACT data from the reports (scores, metrics, WPM, etc.)\n",
    "- When user asks about specific metrics (like WPM, scores, pace), extract and report the EXACT values from the report data\n",
    "- Be concise and to the point\n",
    "- If the data doesn't contain what they're asking for, politely say so\n",
    "- Focus on helping users improve their interview performance\n",
    "\n",
    "User Query: {user_query}\n",
    "\n",
    "{context_text}\n",
    "\n",
    "Please provide a helpful and relevant response based on the report data above.\n",
    "\n",
    "Important: If user asks about specific metrics (WPM, pace, scores, etc.), extract the EXACT values from the reports and provide them in your answer.\n",
    "\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=reports_prompt),\n",
    "            HumanMessage(content=user_query)\n",
    "        ]\n",
    "        response = llm.invoke(messages)\n",
    "        \n",
    "        answer = response.content\n",
    "        print(f\"\\nðŸ“Š Reports Agent Response: {answer}\\n\")\n",
    "        \n",
    "        state[\"response\"] = answer\n",
    "        state[\"messages\"].append(AIMessage(content=answer))\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"I encountered an error while fetching your interview reports: {str(e)}\"\n",
    "        print(f\"\\nâŒ Reports Agent Error: {error_msg}\\n\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        state[\"response\"] = error_msg\n",
    "        state[\"messages\"].append(AIMessage(content=error_msg))\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db89ce",
   "metadata": {},
   "source": [
    "## 8. General Question Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_agent(state: ChatbotState) -> ChatbotState:\n",
    "    \"\"\"\n",
    "    General agent handles greetings, platform questions, and general conversation.\n",
    "    Uses SkillEdge-AI knowledge base context.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_query = state[\"user_query\"]\n",
    "    \n",
    "    # SkillEdge-AI Knowledge Base (matching implemented chatbot)\n",
    "    knowledge_base_context = \"\"\"\n",
    "SkillEdge-AI Platform Information:\n",
    "\n",
    "- SkillEdge-AI is an advanced AI-powered interview simulation platform designed to help job seekers prepare for interviews.\n",
    "- It provides comprehensive feedback on both verbal and non-verbal communication skills.\n",
    "- Offers three main types of interviews: Technical (for programming/technical skills), Behavioral (for soft skills and personality fit), and Resume-based (focusing on professional background).\n",
    "- Provides three detailed reports after each interview:\n",
    "  * Verbal Report: Analyzes answer correctness, depth, domain knowledge\n",
    "  * Non-Verbal Report: Examines speech patterns (WPM, pace, fluency), content quality, confidence level, communication clarity\n",
    "  * Overall Report: Combines both analyses with actionable insights and improvement recommendations\n",
    "- Uses advanced AI technologies including speech recognition, natural language processing, and machine learning.\n",
    "- Helps improve interview performance by providing objective feedback on speaking pace, clarity, confidence, and content quality.\n",
    "- Perfect for job seekers at any career level, students preparing for campus placements, professionals switching careers.\n",
    "\"\"\"\n",
    "    \n",
    "    # System prompt for general agent\n",
    "    general_prompt = f\"\"\"You are SkillEdge-AI Assistant, a friendly assistant for the SkillEdge-AI interview preparation platform.\n",
    "\n",
    "Platform Information:\n",
    "{knowledge_base_context}\n",
    "\n",
    "Guidelines:\n",
    "- Be helpful, professional, and encouraging\n",
    "- Provide accurate information about SkillEdge-AI platform features and benefits\n",
    "- If greeting, greet warmly\n",
    "- If asking about platform, explain clearly using the information above\n",
    "- Keep responses concise and conversational (2-3 sentences)\n",
    "- If question is outside platform scope, politely acknowledge and redirect to platform features\n",
    "\n",
    "User Question: {user_query}\n",
    "\n",
    "Provide a helpful response:\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=general_prompt),\n",
    "        HumanMessage(content=user_query)\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    answer = response.content\n",
    "    print(f\"\\nðŸ’¬ General Agent Response: {answer}\\n\")\n",
    "    \n",
    "    state[\"response\"] = answer\n",
    "    state[\"messages\"].append(AIMessage(content=answer))\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1c8d9",
   "metadata": {},
   "source": [
    "## 9. Router Function - Conditional Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_query(state: ChatbotState) -> Literal[\"resume_agent\", \"reports_agent\", \"general_agent\"]:\n",
    "    \"\"\"\n",
    "    Router function that determines which agent node to visit next based on supervisor's decision.\n",
    "    \"\"\"\n",
    "    route = state[\"route\"]\n",
    "    \n",
    "    if route == \"resume\":\n",
    "        return \"resume_agent\"\n",
    "    elif route == \"reports\":\n",
    "        return \"reports_agent\"\n",
    "    else:\n",
    "        return \"general_agent\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783ee0a",
   "metadata": {},
   "source": [
    "## 10. Build LangGraph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph with async support\n",
    "workflow = StateGraph(ChatbotState)\n",
    "\n",
    "# Add nodes (wrap async functions)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "workflow.add_node(\"resume_agent\", resume_agent)\n",
    "workflow.add_node(\"reports_agent\", reports_agent)\n",
    "workflow.add_node(\"general_agent\", general_agent)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Add conditional edges from supervisor to sub-agents\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    route_query,\n",
    "    {\n",
    "        \"resume_agent\": \"resume_agent\",\n",
    "        \"reports_agent\": \"reports_agent\",\n",
    "        \"general_agent\": \"general_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# All sub-agents lead to END\n",
    "workflow.add_edge(\"resume_agent\", END)\n",
    "workflow.add_edge(\"reports_agent\", END)\n",
    "workflow.add_edge(\"general_agent\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"âœ… LangGraph workflow compiled successfully with database integration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f4f82",
   "metadata": {},
   "source": [
    "## 11. Visualize the Graph (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13d7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to visualize the graph\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Unable to visualize graph: {e}\")\n",
    "    print(\"Graph structure: supervisor -> [resume_agent | reports_agent | general_agent] -> END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d39416",
   "metadata": {},
   "source": [
    "## 12. Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab162ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global conversation history storage\n",
    "conversation_histories = {}\n",
    "\n",
    "async def chat(user_query: str, user_id: str = \"69036f582c287be569c54623\", conversation_id: str = \"default\"):\n",
    "    \"\"\"\n",
    "    Main chat function that processes user queries through the LangGraph workflow.\n",
    "    Now with conversation history persistence!\n",
    "    \n",
    "    Args:\n",
    "        user_query: The user's question or message\n",
    "        user_id: MongoDB ObjectId (e.g., \"69036f582c287be569c54623\")\n",
    "        conversation_id: Unique identifier for this conversation (maintains context)\n",
    "    \n",
    "    Returns:\n",
    "        The chatbot's response\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸ§‘ User: {user_query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get or initialize conversation history for this conversation\n",
    "    if conversation_id not in conversation_histories:\n",
    "        conversation_histories[conversation_id] = []\n",
    "    \n",
    "    conversation_history = conversation_histories[conversation_id]\n",
    "    \n",
    "    # Add current user message to history\n",
    "    conversation_history.append(HumanMessage(content=user_query))\n",
    "    \n",
    "    # Build context from last 10 messages for the supervisor\n",
    "    context_messages = conversation_history[-10:]  # Last 10 messages\n",
    "    \n",
    "    # Build a context summary for the supervisor to understand previous conversation\n",
    "    if len(conversation_history) > 1:\n",
    "        recent_context = \"\\n\".join([\n",
    "            f\"{'User' if isinstance(msg, HumanMessage) else 'Assistant'}: {msg.content[:100]}...\"\n",
    "            for msg in conversation_history[-4:-1]  # Last 3 exchanges (exclude current)\n",
    "        ])\n",
    "        context_aware_query = f\"[Previous context: {recent_context}]\\n\\nCurrent query: {user_query}\"\n",
    "    else:\n",
    "        context_aware_query = user_query\n",
    "    \n",
    "    # Initialize state with conversation history\n",
    "    initial_state = {\n",
    "        \"messages\": context_messages,\n",
    "        \"user_query\": context_aware_query,  # Include context for better routing\n",
    "        \"route\": \"\",\n",
    "        \"response\": \"\",\n",
    "        \"user_id\": user_id\n",
    "    }\n",
    "    \n",
    "    # Run the workflow\n",
    "    result = await app.ainvoke(initial_state)\n",
    "    \n",
    "    # Add assistant response to conversation history\n",
    "    conversation_history.append(AIMessage(content=result['response']))\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"ðŸ¤– Final Response: {result['response']}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return result[\"response\"]\n",
    "\n",
    "def clear_conversation(conversation_id: str = \"default\"):\n",
    "    \"\"\"Clear conversation history for a given conversation ID\"\"\"\n",
    "    if conversation_id in conversation_histories:\n",
    "        del conversation_histories[conversation_id]\n",
    "        print(f\"âœ… Cleared conversation history for: {conversation_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf0421",
   "metadata": {},
   "source": [
    "## 13. Test Cases - Resume Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bababc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test resume-related queries\n",
    "# # Note: Replace \"test_user_123\" with an actual user ID that has a resume indexed\n",
    "# await chat(\"What skills are mentioned in my resume?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a05ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# await chat(\"Can you tell me about my work experience?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d23333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# await chat(\"What projects have I worked on?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e9f513",
   "metadata": {},
   "source": [
    "## 14. Test Cases - Reports Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958db540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reports-related queries\n",
    "# Note: Replace \"test_user_123\" with an actual user ID that has interview reports\n",
    "# await chat(\"How did I perform in my last interview?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b231e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test WPM query (should now return specific data from nonverbal report)\n",
    "# await chat(\"What is my WPM?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test general platform question\n",
    "# await chat(\"What is SkillEdge-AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c46788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test resume query\n",
    "# await chat(\"What programming languages do I know?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test with top_k=3 (like production website)\n",
    "# user_id = \"69036f582c287be569c54623\"\n",
    "# query = \"which programming languages do i know?\"\n",
    "\n",
    "# # Search with top_k=3 (production setting)\n",
    "# results = await resume_rag.search_user_resume(user_id, query, top_k=3)\n",
    "\n",
    "# print(f\"Production setting (top_k=3) - Found {len(results)} chunks:\\n\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# for i, result in enumerate(results, 1):\n",
    "#     print(f\"\\nðŸ“„ Chunk {i} (Similarity: {result.get('similarity_score', 'N/A')}):\")\n",
    "#     print(\"-\"*80)\n",
    "#     print(result['content'])\n",
    "#     print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad72feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with production query - \"which programming languages do i know?\"\n",
    "# clear_conversation()  # Start fresh\n",
    "# await chat(\"which programming languages do i know?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230fc146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test negative case - verify it correctly says NO to Java and Go\n",
    "# await chat(\"do i know java?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcee96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Go as well\n",
    "# await chat(\"do i know go?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# await chat(\"Show me my interview analytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312565f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# await chat(\"What feedback did I receive on my interviews?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e3b0c",
   "metadata": {},
   "source": [
    "## 15. Test Cases - General Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8152936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test general queries\n",
    "# await chat(\"Hello! How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf6049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# await chat(\"What is this platform about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# await chat(\"Thanks for your help!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f1e783",
   "metadata": {},
   "source": [
    "## 16. Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d150e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive loop for testing\n",
    "print(\"\\nðŸŽ‰ Interactive Chatbot with Database Integration (type 'quit' to exit)\\n\")\n",
    "print(\"ðŸ’¡ Tip: Change user_id to test with different users\\n\")\n",
    "\n",
    "current_user_id = \"69036f582c287be569c54623\"  # Change this to actual user ID\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "        print(\"ðŸ‘‹ Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    response = await chat(user_input, user_id=current_user_id)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
